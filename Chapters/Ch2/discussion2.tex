\section{Summary and discussion}
This study explores a new framework to the problem of phoneme similarity. Using learning algorithms, it derives a feature-based metric function from phoneme-confusion data. In doing so, it provides means to quantify the contribution of subphonemic features to the overall similarity. Moreover, since feature weights compete among themselves over explaining empirical perceptual distances (section 2.2.2.1), the resulting weights are interpreted as perceptually saliencies of features.

The study relies on several simplifying assumptions that can be alleviated in future studies: for computational convenience, it assumes a linear mapping between the feature and similarity spaces. However, the suggested framework provides freedom in the choice of the abstract form of the metric function, which, in general, can incorporate any type of non-linearity (Eq. 2.1). Second, the study assumes that perceptual similarities are symmetric, despite accumulating opposing evidence. However, asymmetric metrics, namely - quasimetrics, can be learned using the same approach. Once the form of the quasimetric is chosen, its parameters can be learned from the data, in the same way, subject to minor modifications of the learning algorithms. 

We explored with two classic phoneme-confusion datasets in English \citep{NicelyMiller1955, Luce1987} and two common feature theories (\citealp{ChomskyHalle1968}, and articulatory dimensions). We then derived a metric function for each dataset and feature theory, and described the resulting order among subphonemic features with respect to their perceptual saliencies. The four leading groups of subphonemic features in English, in descending order, are: voicing, nasality, distributed-stridents, and approximants. Favorably, this is in accordance with previous studies and acoustic considerations: the voicing and nasality features have been demonstrated as highly perceptually discriminating using information-theory measures \citep{NicelyMiller1955}. As for distributed-stridents, this class of phonemes have relatively high energy in their waveform, which may explain their relatively high weight. Acoustic analyses conducted by \citep[see][Figure 15]{Mielke2012} showed that stridents are distinguished from other phonemes along the first principal component of acoustic distances, which is interpreted as dominance of high-frequency acoustic energy. However, a distinction between distributed stridents and non-distributed stridents was not observed in this analysis. The second principal component of this analysis, which is interpreted as dominance of low-frequency acoustic energy, distinguishes the nasal and approximant phonemes /n/, /m/, /w/, /j/, /l/, /r/ and /h/ from the other phonemes in the datasets, in this order. This shows that the relatively high weight of approximant features and the fricative glottal /h/ is also grounded in acoustics.

Confusion-rate results among Hebrew phonemes were reported. The new Hebrew dataset was analyzed and compared to the English ones, revealing a discrepancy between Hebrew and English with respect to subphonemic feature weights. In particular, a major difference with respect to voicing was found. We suggest two possible sources for this difference. First, it can be accounted for by redundant cues for unvoiced plosives in English that are absent in Hebrew. A redundant cue is an articulatory-independent mechanism to enhance a primary cue in the signal. In particular, \citet{stevens1989primary} suggests that the feature [-voice] is enhanced by glottal opening (aspiration) in English, which prolongs the duration of the voiceless interval, thus rendering voiceless stops more distinguishable from voiced stops. Hebrew and other languages (e.g., French) do not employ this enhancement. Another explanation for the different weight of voicing is the differences in voicing onset times (VOT) \citep{Laufer1998} between the two languages. VOTs of voiced stops in Hebrew are more negative than in English, which may affect perceptual discrimination.  Taken together, this result is another evidence that the metric space may differ across languages.


In sum, this study is a first demonstration of the benefits of a data-driven approach to the problem of phoneme similarity. Its general framework was shown to have several potential advantages, and provides means to quantify various aspects of phoneme similarity. In particular, it reveals an order among subphonemic features with respect to their perceptually discriminative power, suggesting the first quantification of their contribution to the overall similarity. The approach enables the integration of various effects, such as context or asymmetry, into its framework, and is compatible with various feature theories and noise characteristics.